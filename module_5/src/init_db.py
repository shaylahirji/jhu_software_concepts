"""
This script initializes the database schema and loads a JSON file containing 
extended applicant data into the database.

It utilizes psycopg SQL composition to safely create the database infrastructure
and then calls the `load_json_to_db` function from the `load_data` module.

Usage:
    python init_db.py

It is intended to be run as a standalone script, typically with higher-level 
privileges than the standard web application worker.
"""

import psycopg
from psycopg import sql
from config import get_db_connection
from load_data import load_json_to_db

def setup_schema():
    """
    Creates the necessary database tables and constraints using SQL composition.
    This ensures the database is prepared for the least-privilege app_worker.

    :return: None
    :rtype: None
    :raises psycopg.Error: Raised if there is an issue creating tables or constraints.
    """
    connection = get_db_connection()
    try:
        with connection.cursor() as cur:
            # Step 2: Use SQL Identifier for table creation
            create_stmt = sql.SQL("""
                CREATE TABLE IF NOT EXISTS {table} (
                    p_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    program TEXT,
                    comments TEXT,
                    date_added DATE,
                    url TEXT UNIQUE,
                    status TEXT,
                    term TEXT,
                    us_or_international TEXT,
                    gpa FLOAT,
                    gre FLOAT,
                    gre_v FLOAT,
                    gre_aw FLOAT,
                    degree TEXT,
                    llm_generated_program TEXT,
                    llm_generated_university TEXT
                );
            """).format(table=sql.Identifier("applicantdata"))

            cur.execute(create_stmt)

            # Step 2: Use SQL Literal for inherent limit check of constraints
            check_stmt = sql.SQL("""
                SELECT 1 FROM pg_constraint 
                WHERE conname = {con} LIMIT {lim};
            """).format(
                con=sql.Literal('applicantdata_url_key'),
                lim=sql.Literal(1)
            )
            cur.execute(check_stmt)

            if not cur.fetchone():
                # Apply unique constraint if it doesn't exist
                alter_stmt = sql.SQL(
                    "ALTER TABLE {table} ADD CONSTRAINT {con} UNIQUE (url);"
                ).format(
                    table=sql.Identifier("applicantdata"),
                    con=sql.Identifier("applicantdata_url_key")
                )
                cur.execute(alter_stmt)

        connection.commit()
        print("[OK] Database schema initialized successfully.")
    except psycopg.Error as e:
        print(f"[ERROR] Database initialization failed: {e}")
    finally:
        connection.close()

def run_init():
    """
    Triggers the schema setup and the JSON loading process by passing the path 
    of the LLM extended applicant data to the database loader.

    :return: None.
    :rtype: None
    :raises FileNotFoundError: Raised if the specified JSON file path does not exist.
    :raises psycopg.Error: Raised if there is an issue during the database insertion.
    """
    # Initialize the table and constraints first
    setup_schema()

    # Load the initial data using the refactored load_data module
    load_json_to_db("Web_Scrape/raw_data/llm_extended_applicant_data.json")

if __name__ == "__main__": #pragma: no cover
    run_init()
